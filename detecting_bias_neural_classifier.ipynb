{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "detecting_bias_neural_classifier.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyP1+ZuYOgLavcOwgyCIjjkJ",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/drew-walkerr/DetectingBias/blob/main/detecting_bias_neural_classifier.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Tutorial Links from class\n",
        "1. https://www.kaggle.com/deshwalmahesh/nlp-beginner-1-rnn-lstm-gru-embeddings-glove\n",
        "2. https://www.kaggle.com/kredy10/simple-lstm-for-text-classification \n",
        "\n",
        "3. https://machinelearningmastery.com/roc-curves-and-precision-recall-curves-for-classification-in-python/\n"
      ],
      "metadata": {
        "id": "DVY8IYo38A2t"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "OyMPa7Wn5Ymy"
      },
      "outputs": [],
      "source": [
        "# This is a BoW classifier to detect the presence of provider scare quotes in provider clinical notes\n",
        "\n",
        "import pandas as pd\n",
        "import numpy\n",
        "from sklearn import model_selection\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.model_selection import StratifiedKFold\n",
        "from sklearn import feature_selection\n",
        "import numpy as np\n",
        "\n",
        "import tensorflow_datasets as tfds\n",
        "import tensorflow as tf\n",
        "\n",
        "tfds.disable_progress_bar()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "id": "Mp1Z7P9pYRSK"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "\n",
        "def plot_graphs(history, metric):\n",
        "  plt.plot(history.history[metric])\n",
        "  plt.plot(history.history['val_'+metric], '')\n",
        "  plt.xlabel(\"Epochs\")\n",
        "  plt.ylabel(metric)\n",
        "  plt.legend([metric, 'val_'+metric])"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Load in data\n",
        "gold_standard = pd.read_csv(\"gold_standard_bias_annotation_doc_training.csv\")\n"
      ],
      "metadata": {
        "id": "bLqa2nI-AHYp"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Mini HW 9/10—Neural classifier —Instructions:\n",
        "Due 10 Dec\n",
        "In this two part HW, you will split your dataset into training/test sets, and then build a neu-\n",
        "ral classifier of your choice. Recommend LSTM but for an extra challenge you can also consider a transformer/RoBERTA if you prefer (esp if you are working with a low resource language). Do this homework in python only. You will need to move to google co-lab if you haven’t already and take\n",
        "advantage of a GPU.\n",
        "\n",
        "1. First, for HW 8, set up your neural model. You will likely want to use the same training/test split\n",
        "as before, but if you make any adjustments make sure to note the reason. You will need to include\n",
        "Glove embeddings as a feature of your LSTM model. Consider the many available tutorials such\n",
        "as this or this. Consider at least two specifications of your neural model, and write up what you\n",
        "did and why.\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "zYsMrlYE5ZIl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Split\n",
        "seed = 1234\n",
        "X = gold_standard['Sentence']\n",
        "y = gold_standard['quote_use']\n",
        "#Hyperparameters\n",
        "max_features_model = 3000\n",
        "splits = 5\n",
        "model_name = \"RNN\"\n",
        "#Splitting and model\n",
        "skf = StratifiedKFold(n_splits=splits, random_state=seed, shuffle= True)\n",
        "for train_index, test_index in skf.split(X, y):\n",
        "    X_train, X_test = X[train_index], X[test_index]\n",
        "    y_train, y_test = y[train_index], y[test_index]\n",
        "\n",
        "max_words = 10000\n",
        "max_len = 150\n",
        "tok = Tokenizer(num_words=max_words)\n",
        "tok.fit_on_texts(X_train)\n",
        "sequences = tok.texts_to_sequences(X_train)\n",
        "sequences_matrix = sequence.pad_sequences(sequences,maxlen=max_len)\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "RyClY5Ym5e2T"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def RNN():\n",
        "    inputs = Input(name='inputs',shape=[max_len])\n",
        "    layer = Embedding(max_words,50,input_length=max_len)(inputs)\n",
        "    layer = LSTM(64)(layer)\n",
        "    layer = Dense(256,name='FC1')(layer)\n",
        "    layer = Activation('relu')(layer)\n",
        "    layer = Dropout(0.5)(layer)\n",
        "    layer = Dense(1,name='out_layer')(layer)\n",
        "    layer = Activation('sigmoid')(layer)\n",
        "    model = Model(inputs=inputs,outputs=layer)\n",
        "    return model"
      ],
      "metadata": {
        "id": "nzrB6wNu25Q3"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = RNN()\n",
        "model.summary()\n",
        "model.compile(loss='binary_crossentropy',optimizer=RMSprop(),metrics=['accuracy'])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yEvN5LcM4OgX",
        "outputId": "e308efab-d685-4dac-c18e-65258016ed2a"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " inputs (InputLayer)         [(None, 150)]             0         \n",
            "                                                                 \n",
            " embedding (Embedding)       (None, 150, 50)           500000    \n",
            "                                                                 \n",
            " lstm (LSTM)                 (None, 64)                29440     \n",
            "                                                                 \n",
            " FC1 (Dense)                 (None, 256)               16640     \n",
            "                                                                 \n",
            " activation (Activation)     (None, 256)               0         \n",
            "                                                                 \n",
            " dropout (Dropout)           (None, 256)               0         \n",
            "                                                                 \n",
            " out_layer (Dense)           (None, 1)                 257       \n",
            "                                                                 \n",
            " activation_1 (Activation)   (None, 1)                 0         \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 546,337\n",
            "Trainable params: 546,337\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.fit(sequences_matrix,y_train,batch_size=128,epochs=10,\n",
        "          validation_split=0.2,callbacks=[EarlyStopping(monitor='val_loss',min_delta=0.0001)])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lqA1cZri4YdD",
        "outputId": "c92fc4e6-fa25-4d88-8a04-de0af8f10323"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "3/3 [==============================] - 4s 473ms/step - loss: 0.6468 - accuracy: 0.2032 - val_loss: 0.4403 - val_accuracy: 0.2660\n",
            "Epoch 2/10\n",
            "3/3 [==============================] - 1s 217ms/step - loss: -0.1544 - accuracy: 0.1658 - val_loss: -2.3928 - val_accuracy: 0.2660\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f829a87c050>"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_sequences = tok.texts_to_sequences(X_test)\n",
        "test_sequences_matrix = sequence.pad_sequences(test_sequences,maxlen=max_len)\n",
        "y_pred_class = model.predict(test_sequences_matrix)"
      ],
      "metadata": {
        "id": "EigqzTSj6VFz"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "accr = model.evaluate(test_sequences_matrix,y_test)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-OuGyWGQ6XpV",
        "outputId": "7106f496-c21f-4908-bd2e-d069d557e833"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "4/4 [==============================] - 0s 21ms/step - loss: -1.7684 - accuracy: 0.1880\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(accr)\n",
        "print(metrics.classification_report(y_test, test_sequences_matrix, digits=5))\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 404
        },
        "id": "n1wPMJsMvLSf",
        "outputId": "f9203b17-b9e9-4117-801e-b74256c2e972"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[-1.7683783769607544, 0.18803419172763824]\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-18-1ec3bcff16b1>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maccr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmetrics\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclassification_report\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_sequences\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_sequences_matrix\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdigits\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\u001b[0m in \u001b[0;36mclassification_report\u001b[0;34m(y_true, y_pred, labels, target_names, sample_weight, digits, output_dict, zero_division)\u001b[0m\n\u001b[1;32m   2074\u001b[0m     \"\"\"\n\u001b[1;32m   2075\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2076\u001b[0;31m     \u001b[0my_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_check_targets\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2077\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2078\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mlabels\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\u001b[0m in \u001b[0;36m_check_targets\u001b[0;34m(y_true, y_pred)\u001b[0m\n\u001b[1;32m     83\u001b[0m     \"\"\"\n\u001b[1;32m     84\u001b[0m     \u001b[0mcheck_consistent_length\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 85\u001b[0;31m     \u001b[0mtype_true\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtype_of_target\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     86\u001b[0m     \u001b[0mtype_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtype_of_target\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     87\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/sklearn/utils/multiclass.py\u001b[0m in \u001b[0;36mtype_of_target\u001b[0;34m(y)\u001b[0m\n\u001b[1;32m    299\u001b[0m         ):\n\u001b[1;32m    300\u001b[0m             raise ValueError(\n\u001b[0;32m--> 301\u001b[0;31m                 \u001b[0;34m\"You appear to be using a legacy multi-label data\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    302\u001b[0m                 \u001b[0;34m\" representation. Sequence of sequences are no\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    303\u001b[0m                 \u001b[0;34m\" longer supported; use a binary array or sparse\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: You appear to be using a legacy multi-label data representation. Sequence of sequences are no longer supported; use a binary array or sparse matrix instead - the MultiLabelBinarizer transformer can convert to this format."
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print('Test set\\n  Loss: {:0.3f}\\n  Accuracy: {:0.3f}'.format(accr[0],accr[1]))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "euftZIsA6dBv",
        "outputId": "4323c434-f158-4253-c830-1f8fe98fad58"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test set\n",
            "  Loss: -1.768\n",
            "  Accuracy: 0.188\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "2. Next, for HW 10, estimate the F1 score and plot a precision/recall curve to compare your neural\n",
        "model specifications to your BOW model in the same plot. Consider using a tutorial (e.g. here).\n",
        "Write up in overleaf what you did and why, and include the plot that compares your neural and\n",
        "BOW models in your write up on overleaf and submit on Canvas.\n"
      ],
      "metadata": {
        "id": "vVViX_EJ5k1d"
      }
    }
  ]
}